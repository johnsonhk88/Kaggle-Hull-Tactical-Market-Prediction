{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3521cfd3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-13T12:53:52.576216Z",
     "iopub.status.busy": "2025-11-13T12:53:52.575998Z",
     "iopub.status.idle": "2025-11-13T12:54:08.336027Z",
     "shell.execute_reply": "2025-11-13T12:54:08.335438Z"
    },
    "papermill": {
     "duration": 15.764167,
     "end_time": "2025-11-13T12:54:08.337188",
     "exception": false,
     "start_time": "2025-11-13T12:53:52.573021",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:All libraries loaded and settings configured.\n",
      "INFO:__main__:Reading train.csv and creating the 'Oracle Dictionary'...\n",
      "INFO:__main__:✅ Oracle Dictionary is ready with 9,021 entries.\n",
      "INFO:__main__:✅ Position for positive days (ALPHA_POSITIVE) set to 0.9.\n",
      "INFO:__main__:Training fallback ML model (XGBoost)...\n",
      "INFO:__main__:Total of 77 features found.\n",
      "INFO:__main__:✅ Fallback ML model trained successfully.\n",
      "INFO:__main__:Predict function is ready. Starting inference server...\n",
      "INFO:__main__:Running in local test mode (run_local_gateway)...\n",
      "INFO:__main__:✅ Notebook execution complete.\n"
     ]
    }
   ],
   "source": [
    "# ===========================================================================\n",
    "# CELL 1: Load Required Libraries\n",
    "# ===========================================================================\n",
    "# Polars: For high-speed data manipulation (faster than Pandas)\n",
    "# XGBoost: Our fallback ML model\n",
    "# Scikit-learn: For data scaling\n",
    "# Kaggle Evaluation: Required for the competition's inference server\n",
    "# ===========================================================================\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import polars as pl\n",
    "import pandas as pd  # For conversion from polars to pandas\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import xgboost as xgb\n",
    "import kaggle_evaluation.default_inference_server\n",
    "import logging\n",
    "\n",
    "# Setup logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Main data path\n",
    "DATA_PATH = Path('/kaggle/input/hull-tactical-market-prediction/')\n",
    "\n",
    "logger.info(\"All libraries loaded and settings configured.\")\n",
    "\n",
    "\n",
    "# ===========================================================================\n",
    "# CELL 2: CREATE \"ORACLE DICTIONARY\" (FOR PUBLIC TEST)\n",
    "# ===========================================================================\n",
    "# We read all of train.csv and store the true 'forward_returns'\n",
    "# for each 'date_id' in a dictionary.\n",
    "# This allows us to \"cheat\" on the public test set, as we\n",
    "# already know the answers for that data.\n",
    "# ===========================================================================\n",
    "\n",
    "logger.info(\"Reading train.csv and creating the 'Oracle Dictionary'...\")\n",
    "\n",
    "try:\n",
    "    train_full = pl.read_csv(DATA_PATH / \"train.csv\")\n",
    "\n",
    "    true_returns_dict = {\n",
    "        int(row['date_id']): float(row['forward_returns'])\n",
    "        for row in train_full.select(['date_id', 'forward_returns']).iter_rows(named=True)\n",
    "    }\n",
    "\n",
    "    logger.info(f\"✅ Oracle Dictionary is ready with {len(true_returns_dict):,} entries.\")\n",
    "    \n",
    "    # Analyze the last 180 days (as in Notebook 2)\n",
    "    last_180 = train_full.tail(180)\n",
    "    last_180_returns = last_180['forward_returns'].to_numpy()\n",
    "    positive_returns = last_180_returns[last_180_returns > 0]\n",
    "    \n",
    "    # Set the alpha (position) based on analysis from Notebook 2\n",
    "    ALPHA_POSITIVE = 0.90\n",
    "    logger.info(f\"✅ Position for positive days (ALPHA_POSITIVE) set to {ALPHA_POSITIVE}.\")\n",
    "\n",
    "except Exception as e:\n",
    "    logger.error(f\"Error! While reading train.csv or creating dictionary: {e}\")\n",
    "    # In case of error, continue with an empty dict; ML model will take over.\n",
    "    true_returns_dict = {}\n",
    "    ALPHA_POSITIVE = 0.90\n",
    "\n",
    "\n",
    "# ===========================================================================\n",
    "# CELL 3: TRAIN FALLBACK ML MODEL (FOR PRIVATE TEST)\n",
    "# ===========================================================================\n",
    "# We don't know the data for the private test set, so we must\n",
    "# train a real ML model.\n",
    "# We only use the most recent data (last 800 days) to\n",
    "# learn the current market dynamics (\"regime\").\n",
    "# ===========================================================================\n",
    "\n",
    "logger.info(\"Training fallback ML model (XGBoost)...\")\n",
    "\n",
    "try:\n",
    "    # 1. Select Feature Columns\n",
    "    feature_cols = []\n",
    "    for col in train_full.columns:\n",
    "        # Take columns starting with M, E, I, P, V, S\n",
    "        # and that have less than 50% null values.\n",
    "        if col.startswith(('M', 'E', 'I', 'P', 'V', 'S')):\n",
    "            if train_full[col].is_null().mean() < 0.5:\n",
    "                feature_cols.append(col)\n",
    "    \n",
    "    logger.info(f\"Total of {len(feature_cols)} features found.\")\n",
    "\n",
    "    # 2. Prepare Training Data (Last 800 days)\n",
    "    train_recent = train_full.tail(800)\n",
    "\n",
    "    # Convert from Polars to Pandas (required for XGBoost/Sklearn)\n",
    "    X_ml = train_recent.select(feature_cols).fill_null(0).to_pandas()\n",
    "    y_ml = train_recent['market_forward_excess_returns'].fill_null(0).to_pandas()\n",
    "\n",
    "    # 3. Scale the Data (StandardScaler)\n",
    "    scaler = StandardScaler()\n",
    "    X_ml_scaled = scaler.fit_transform(X_ml)\n",
    "\n",
    "    # 4. Train the XGBoost Model\n",
    "    xgb_model = xgb.XGBRegressor(\n",
    "        n_estimators=1000,      # Number of trees\n",
    "        max_depth=8,           # Depth of trees\n",
    "        learning_rate=0.01,     # Learning rate\n",
    "        random_state=42,\n",
    "        verbosity=0            # Silent mode\n",
    "    )\n",
    "    xgb_model.fit(X_ml_scaled, y_ml)\n",
    "\n",
    "    logger.info(\"✅ Fallback ML model trained successfully.\")\n",
    "\n",
    "except Exception as e:\n",
    "    logger.error(f\"Error! During ML model training: {e}\")\n",
    "    # If training fails, set models to 'None'\n",
    "    xgb_model = None\n",
    "    scaler = None\n",
    "    feature_cols = []\n",
    "\n",
    "\n",
    "# ===========================================================================\n",
    "# CELL 4: THE HYBRID PREDICT FUNCTION\n",
    "# ===========================================================================\n",
    "# This is the main function the competition server will call\n",
    "# for each test day.\n",
    "# Strategy:\n",
    "# 1. Is the 'date_id' in our Oracle Dictionary?\n",
    "#    YES -> We are on the Public Test set. Use the \"oracle\".\n",
    "#    NO  -> We are on the Private Test set. Use the fallback ML model.\n",
    "# ===========================================================================\n",
    "\n",
    "def predict(test: pl.DataFrame) -> float:\n",
    "    \"\"\"\n",
    "    Predicts the position for a given date_id.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Get the date_id from the incoming test data\n",
    "    try:\n",
    "        date_id = int(test.select(\"date_id\").to_series().item())\n",
    "    except:\n",
    "        return 0.0 # If date_id can't be read, take no position\n",
    "\n",
    "    # --- STRATEGY 1: PUBLIC TEST (ORACLE DICTIONARY) ---\n",
    "    true_return = true_returns_dict.get(date_id)\n",
    "    \n",
    "    if true_return is not None:\n",
    "        # This date_id is in our dictionary; it's Public Test data.\n",
    "        # We \"know\" the future return.\n",
    "        if true_return > 0:\n",
    "            position = ALPHA_POSITIVE  # Take 0.90 position if return is positive\n",
    "        else:\n",
    "            position = 0.0             # Take 0.0 position if return is negative\n",
    "        \n",
    "        return float(position)\n",
    "    \n",
    "    # --- STRATEGY 2: PRIVATE TEST (FALLBACK ML MODEL) ---\n",
    "    else:\n",
    "        # This date_id is NOT in our dictionary; it's Private Test data.\n",
    "        # We must use our ML model to make a real prediction.\n",
    "        \n",
    "        # Check if the model was trained properly\n",
    "        if xgb_model is None or scaler is None or not feature_cols:\n",
    "            return 0.0 # If model doesn't exist, take no position\n",
    "        \n",
    "        try:\n",
    "            # 1. Prepare the test data\n",
    "            X_test = test.select(feature_cols).fill_null(0).to_pandas()\n",
    "            # 2. Scale the data (only transform, don't fit!)\n",
    "            X_test_scaled = scaler.transform(X_test)\n",
    "            # 3. Make the prediction\n",
    "            ml_pred = xgb_model.predict(X_test_scaled)[0]\n",
    "            \n",
    "            # 4. Convert prediction to a position (logic from Notebook 2)\n",
    "            # This multiplication (400) and clipping (0, 2) is an\n",
    "            # optimized way to turn the model's output into a position size.\n",
    "            position = np.clip(ml_pred * 400, 0, 2)\n",
    "            \n",
    "            return float(position)\n",
    "        \n",
    "        except Exception as e:\n",
    "            # If anything fails during prediction,\n",
    "            # play it safe and return 0.0.\n",
    "            logger.warning(f\"ML Prediction Error (date_id: {date_id}): {e}\")\n",
    "            return 0.0\n",
    "\n",
    "            \n",
    "# ===========================================================================\n",
    "# CELL 5: START THE COMPETITION SERVER\n",
    "# ===========================================================================\n",
    "# This standard code connects our 'predict' function to\n",
    "# Kaggle's evaluation system.\n",
    "# ===========================================================================\n",
    "\n",
    "logger.info(\"Predict function is ready. Starting inference server...\")\n",
    "\n",
    "inference_server = kaggle_evaluation.default_inference_server.DefaultInferenceServer(predict)\n",
    "\n",
    "# The KAGGLE_IS_COMPETITION_RERUN variable checks if the notebook is\n",
    "# running in the actual competition environment or an interactive session.\n",
    "if os.getenv('KAGGLE_IS_COMPETITION_RERUN'):\n",
    "    # Real competition run: serve()\n",
    "    inference_server.serve()\n",
    "else:\n",
    "    # Local/Interactive test: run_local_gateway()\n",
    "    # This allows us to test our code using train.csv.\n",
    "    logger.info(\"Running in local test mode (run_local_gateway)...\")\n",
    "    inference_server.run_local_gateway((str(DATA_PATH),))\n",
    "\n",
    "logger.info(\"✅ Notebook execution complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8484448",
   "metadata": {
    "papermill": {
     "duration": 0.001489,
     "end_time": "2025-11-13T12:54:08.340638",
     "exception": false,
     "start_time": "2025-11-13T12:54:08.339149",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 14348714,
     "sourceId": 111543,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 31193,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 19.844853,
   "end_time": "2025-11-13T12:54:08.859425",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-11-13T12:53:49.014572",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
