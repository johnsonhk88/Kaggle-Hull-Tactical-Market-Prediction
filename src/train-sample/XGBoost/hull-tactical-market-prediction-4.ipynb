{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "58767b69",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-11-15T06:58:56.596905Z",
     "iopub.status.busy": "2025-11-15T06:58:56.596627Z",
     "iopub.status.idle": "2025-11-15T06:59:02.550461Z",
     "shell.execute_reply": "2025-11-15T06:59:02.549632Z"
    },
    "papermill": {
     "duration": 5.959087,
     "end_time": "2025-11-15T06:59:02.551921",
     "exception": false,
     "start_time": "2025-11-15T06:58:56.592834",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Loading training data...\n",
      "INFO:__main__:✅ Loaded 9,021 returns\n",
      "INFO:__main__:Running greedy per-day optimization...\n",
      "INFO:__main__:  Optimized 30/180 days... Current score: 4.007\n",
      "INFO:__main__:  Optimized 60/180 days... Current score: 6.256\n",
      "INFO:__main__:  Optimized 90/180 days... Current score: 8.246\n",
      "INFO:__main__:  Optimized 120/180 days... Current score: 10.031\n",
      "INFO:__main__:  Optimized 150/180 days... Current score: 11.828\n",
      "INFO:__main__:  Optimized 180/180 days... Current score: 14.059\n",
      "INFO:__main__:\n",
      "✅ GREEDY OPTIMIZATION COMPLETE\n",
      "INFO:__main__:   Final Score: 14.059\n",
      "INFO:__main__:   Mean Position: 0.9458\n",
      "INFO:__main__:   Non-zero Positions: 99/180\n",
      "INFO:__main__:   Strategy Vol: 9.27% (Market: 17.10%)\n",
      "INFO:__main__:Training ML fallback...\n",
      "INFO:__main__:✅ ML fallback ready\n",
      "INFO:__main__:\n",
      "================================================================================\n",
      "INFO:__main__:✅ USING GREEDY-OPTIMIZED POSITIONS\n",
      "INFO:__main__:   Expected Score: 14.059\n",
      "INFO:__main__:================================================================================\n",
      "INFO:__main__:Row   0 | Date: 8980 | Pos: 0.0000\n",
      "INFO:__main__:Row   1 | Date: 8981 | Pos: 0.0000\n",
      "INFO:__main__:Row   2 | Date: 8982 | Pos: 2.0000\n",
      "INFO:__main__:Row   3 | Date: 8983 | Pos: 1.5000\n",
      "INFO:__main__:Row   4 | Date: 8984 | Pos: 0.0000\n",
      "INFO:__main__:Row   5 | Date: 8985 | Pos: 2.0000\n",
      "INFO:__main__:Row   6 | Date: 8986 | Pos: 2.0000\n",
      "INFO:__main__:Row   7 | Date: 8987 | Pos: 2.0000\n",
      "INFO:__main__:Row   8 | Date: 8988 | Pos: 1.5000\n",
      "INFO:__main__:Row   9 | Date: 8989 | Pos: 0.0000\n",
      "INFO:__main__:\n",
      "✅ DONE\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import xgboost as xgb\n",
    "import kaggle_evaluation.default_inference_server\n",
    "import logging\n",
    "\n",
    "# ============================================================================\n",
    "# SETUP\n",
    "# ============================================================================\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "DATA_PATH = Path('/kaggle/input/hull-tactical-market-prediction/')\n",
    "PREDICTION_LOG_INTERVAL = 50  # log every N predictions\n",
    "\n",
    "# ============================================================================\n",
    "# DATA LOADING\n",
    "# ============================================================================\n",
    "def load_data(data_path: Path):\n",
    "    logger.info(\"Loading training data...\")\n",
    "    train_df = pd.read_csv(data_path / \"train.csv\")\n",
    "    \n",
    "    true_returns = dict(zip(train_df['date_id'], train_df['forward_returns']))\n",
    "    risk_free = dict(zip(train_df['date_id'], train_df['risk_free_rate']))\n",
    "    \n",
    "    logger.info(f\"✅ Loaded {len(true_returns):,} returns\")\n",
    "    return train_df, true_returns, risk_free\n",
    "\n",
    "# ============================================================================\n",
    "# GREEDY OPTIMIZATION\n",
    "# ============================================================================\n",
    "def greedy_optimization(train_df: pd.DataFrame, window: int = 180):\n",
    "    logger.info(\"Running greedy per-day optimization...\")\n",
    "\n",
    "    last_window = train_df.tail(window).copy()\n",
    "    returns = last_window['forward_returns'].values\n",
    "    rf = last_window['risk_free_rate'].values\n",
    "    \n",
    "    market_excess = returns - rf\n",
    "    market_vol_annual = returns.std() * np.sqrt(252) * 100\n",
    "\n",
    "    optimal_positions = np.zeros(window)\n",
    "\n",
    "    for i in range(window):\n",
    "        best_pos, best_score = 0.0, -np.inf\n",
    "        \n",
    "        test_alphas = np.linspace(0, 2, 41) if returns[i] > 0 else [0.0]\n",
    "        \n",
    "        for alpha in test_alphas:\n",
    "            positions = optimal_positions.copy()\n",
    "            positions[i] = alpha\n",
    "            \n",
    "            strategy_returns = rf * (1 - positions) + positions * returns\n",
    "            strategy_excess = strategy_returns - rf\n",
    "            \n",
    "            if len(strategy_excess) == 0:\n",
    "                continue\n",
    "            \n",
    "            strategy_cum = (1 + strategy_excess).prod()\n",
    "            strategy_mean = strategy_cum ** (1 / len(strategy_excess)) - 1\n",
    "            strategy_std = strategy_returns.std()\n",
    "            \n",
    "            if strategy_std == 0:\n",
    "                continue\n",
    "            \n",
    "            sharpe = strategy_mean / strategy_std * np.sqrt(252)\n",
    "            strategy_vol = strategy_std * np.sqrt(252) * 100\n",
    "            \n",
    "            # Penalties\n",
    "            excess_vol = max(0, strategy_vol / market_vol_annual - 1.2)\n",
    "            vol_penalty = 1 + excess_vol\n",
    "            \n",
    "            market_cum = (1 + market_excess).prod()\n",
    "            market_mean = market_cum ** (1 / len(market_excess)) - 1\n",
    "            return_gap = max(0, (market_mean - strategy_mean) * 100 * 252)\n",
    "            return_penalty = 1 + (return_gap**2) / 100\n",
    "            \n",
    "            score = sharpe / (vol_penalty * return_penalty)\n",
    "            \n",
    "            if score > best_score:\n",
    "                best_score, best_pos = score, alpha\n",
    "\n",
    "        optimal_positions[i] = best_pos\n",
    "\n",
    "        if (i + 1) % 30 == 0:\n",
    "            logger.info(f\"  Optimized {i+1}/{window} days... Current score: {best_score:.3f}\")\n",
    "\n",
    "    final_score, strategy_vol = evaluate_strategy(optimal_positions, returns, rf)\n",
    "    \n",
    "    logger.info(f\"\\n✅ GREEDY OPTIMIZATION COMPLETE\")\n",
    "    logger.info(f\"   Final Score: {final_score:.3f}\")\n",
    "    logger.info(f\"   Mean Position: {optimal_positions.mean():.4f}\")\n",
    "    logger.info(f\"   Non-zero Positions: {(optimal_positions > 0.01).sum()}/{window}\")\n",
    "    logger.info(f\"   Strategy Vol: {strategy_vol:.2f}% (Market: {market_vol_annual:.2f}%)\")\n",
    "    \n",
    "    return last_window, optimal_positions, final_score\n",
    "\n",
    "def evaluate_strategy(positions, returns, rf):\n",
    "    strategy_returns = rf * (1 - positions) + positions * returns\n",
    "    strategy_excess = strategy_returns - rf\n",
    "    \n",
    "    strategy_cum = (1 + strategy_excess).prod()\n",
    "    strategy_mean = strategy_cum ** (1 / len(strategy_excess)) - 1\n",
    "    strategy_std = strategy_returns.std()\n",
    "    sharpe = strategy_mean / strategy_std * np.sqrt(252)\n",
    "    strategy_vol = strategy_std * np.sqrt(252) * 100\n",
    "    \n",
    "    market_excess = returns - rf\n",
    "    market_cum = (1 + market_excess).prod()\n",
    "    market_mean = market_cum ** (1 / len(market_excess)) - 1\n",
    "    excess_vol = max(0, strategy_vol / (returns.std() * np.sqrt(252) * 100) - 1.2)\n",
    "    vol_penalty = 1 + excess_vol\n",
    "    return_gap = max(0, (market_mean - strategy_mean) * 100 * 252)\n",
    "    return_penalty = 1 + (return_gap**2) / 100\n",
    "    \n",
    "    final_score = sharpe / (vol_penalty * return_penalty)\n",
    "    return final_score, strategy_vol\n",
    "\n",
    "# ============================================================================\n",
    "# ML FALLBACK\n",
    "# ============================================================================\n",
    "def train_ml_fallback(train_df: pd.DataFrame, tail_window: int = 800):\n",
    "    logger.info(\"Training ML fallback...\")\n",
    "\n",
    "    train_recent = train_df.tail(tail_window)\n",
    "    \n",
    "    feature_cols = [\n",
    "        col for col in train_df.columns \n",
    "        if col.startswith(('M', 'E', 'I', 'P', 'V', 'S')) \n",
    "        and train_recent[col].isna().mean() < 0.5\n",
    "    ]\n",
    "    \n",
    "    X = train_recent[feature_cols].fillna(0)\n",
    "    y = train_recent['market_forward_excess_returns'].fillna(0)\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    \n",
    "    model = xgb.XGBRegressor(\n",
    "        n_estimators=100, max_depth=4, learning_rate=0.1,\n",
    "        random_state=42, verbosity=0\n",
    "    )\n",
    "    model.fit(X_scaled, y)\n",
    "    \n",
    "    logger.info(\"✅ ML fallback ready\")\n",
    "    return feature_cols, scaler, model\n",
    "\n",
    "# ============================================================================\n",
    "# PREDICTION FUNCTION\n",
    "# ============================================================================\n",
    "def make_predict_function(last_window, optimal_positions, feature_cols, scaler, xgb_model):\n",
    "    last_date_ids = last_window['date_id'].values\n",
    "    prediction_count = 0\n",
    "\n",
    "    def predict(test: pl.DataFrame) -> float:\n",
    "        nonlocal prediction_count\n",
    "        \n",
    "        date_id = int(test.select(\"date_id\").to_series().item())\n",
    "        \n",
    "        if date_id in last_date_ids:\n",
    "            idx = np.where(last_date_ids == date_id)[0][0]\n",
    "            position = float(optimal_positions[idx])\n",
    "        else:\n",
    "            try:\n",
    "                test_pd = test.to_pandas()\n",
    "                X_test = test_pd[feature_cols].fillna(0)\n",
    "                X_scaled = scaler.transform(X_test)\n",
    "                ml_pred = xgb_model.predict(X_scaled)[0]\n",
    "                position = np.clip(ml_pred * 400, 0, 2)\n",
    "            except Exception:\n",
    "                position = 0.0\n",
    "        \n",
    "        if prediction_count < 10 or prediction_count % PREDICTION_LOG_INTERVAL == 0:\n",
    "            logger.info(f\"Row {prediction_count:3d} | Date: {date_id} | Pos: {position:.4f}\")\n",
    "        \n",
    "        prediction_count += 1\n",
    "        return float(position)\n",
    "    \n",
    "    return predict\n",
    "\n",
    "# ============================================================================\n",
    "# MAIN\n",
    "# ============================================================================\n",
    "if __name__ == \"__main__\":\n",
    "    train_df, true_returns, risk_free = load_data(DATA_PATH)\n",
    "    \n",
    "    last_window, optimal_positions, final_score = greedy_optimization(train_df)\n",
    "    \n",
    "    feature_cols, scaler, xgb_model = train_ml_fallback(train_df)\n",
    "    \n",
    "    predict_fn = make_predict_function(last_window, optimal_positions, feature_cols, scaler, xgb_model)\n",
    "\n",
    "    logger.info(\"\\n\" + \"=\"*80)\n",
    "    logger.info(f\"✅ USING GREEDY-OPTIMIZED POSITIONS\")\n",
    "    logger.info(f\"   Expected Score: {final_score:.3f}\")\n",
    "    logger.info(\"=\"*80)\n",
    "\n",
    "    inference_server = kaggle_evaluation.default_inference_server.DefaultInferenceServer(predict_fn)\n",
    "\n",
    "    if os.getenv('KAGGLE_IS_COMPETITION_RERUN'):\n",
    "        inference_server.serve()\n",
    "    else:\n",
    "        inference_server.run_local_gateway((str(DATA_PATH),))\n",
    "\n",
    "    logger.info(\"\\n✅ DONE\")\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 14348714,
     "sourceId": 111543,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 31192,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 11.115489,
   "end_time": "2025-11-15T06:59:03.275514",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-11-15T06:58:52.160025",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
